"""
ä¸‹è½½å’Œæ•´åˆMambaÂ®é¢„è®­ç»ƒæ¨¡å‹
MambaÂ®: Vision Mamba ALSO Needs Registers
é¡¹ç›®åœ°å€: https://wangf3014.github.io/mambar-page/
GitHub: https://github.com/wangf3014/Mamba-Reg
"""
import torch
import torch.nn as nn
import os
import requests
from tqdm import tqdm
import zipfile

def download_file(url, filename):
    """ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"æ­£åœ¨ä¸‹è½½: {filename}")
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(filename, 'wb') as file, tqdm(
        desc=filename,
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
    ) as pbar:
        for chunk in response.iter_content(chunk_size=8192):
            size = file.write(chunk)
            pbar.update(size)
    print(f"âœ… ä¸‹è½½å®Œæˆ: {filename}")

def download_mambar_models():
    """ä¸‹è½½MambaÂ®é¢„è®­ç»ƒæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹ä¸‹è½½MambaÂ®é¢„è®­ç»ƒæ¨¡å‹...")
    
    # MambaÂ®æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼ˆéœ€è¦æ ¹æ®å®é™…å¯ç”¨é“¾æ¥è°ƒæ•´ï¼‰
    models = {
        "mambar_tiny": {
            "url": "https://github.com/wangf3014/Mamba-Reg/releases/download/v1.0/mambar_tiny_patch16_224.pth",
            "description": "MambaÂ®-Tiny (~9M parameters)"
        },
        "mambar_small": {
            "url": "https://github.com/wangf3014/Mamba-Reg/releases/download/v1.0/mambar_small_patch16_224.pth", 
            "description": "MambaÂ®-Small (~28M parameters)"
        },
        "mambar_base": {
            "url": "https://github.com/wangf3014/Mamba-Reg/releases/download/v1.0/mambar_base_patch16_224.pth",
            "description": "MambaÂ®-Base (~98M parameters)"
        }
    }
    
    # åˆ›å»ºé¢„è®­ç»ƒæ¨¡å‹ç›®å½•
    pretrain_dir = "pretrained_models"
    os.makedirs(pretrain_dir, exist_ok=True)
    
    downloaded_models = []
    
    for model_name, info in models.items():
        try:
            filename = os.path.join(pretrain_dir, f"{model_name}.pth")
            print(f"\nğŸ“¥ {info['description']}")
            
            # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶ï¼Œå› ä¸ºå®é™…ä¸‹è½½é“¾æ¥éœ€è¦éªŒè¯
            # å®é™…ä½¿ç”¨æ—¶éœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„ä¸‹è½½é“¾æ¥
            print(f"âš ï¸  æ³¨æ„ï¼šå®é™…ä¸‹è½½é“¾æ¥éœ€è¦ä»å®˜æ–¹GitHubè·å–")
            print(f"ğŸ“ è¯·è®¿é—®: https://github.com/wangf3014/Mamba-Reg")
            
            # åˆ›å»ºå ä½ç¬¦æ–‡ä»¶
            placeholder_content = {
                'model_type': 'mambar',
                'model_name': model_name,
                'note': 'Please download from official GitHub repository',
                'url': info['url']
            }
            torch.save(placeholder_content, filename)
            downloaded_models.append(filename)
            print(f"âœ… å ä½ç¬¦å·²åˆ›å»º: {filename}")
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥ {model_name}: {e}")
    
    return downloaded_models

def download_nvidia_mambavision():
    """ä¸‹è½½NVIDIA MambaVisionæ¨¡å‹ï¼ˆé€šè¿‡Hugging Faceï¼‰"""
    print("\nğŸ¤– å‡†å¤‡ä¸‹è½½NVIDIA MambaVisionæ¨¡å‹...")
    
    try:
        # è¿™é‡Œéœ€è¦å®‰è£…transformersåº“
        print("ğŸ’¡ NVIDIA MambaVisionå¯é€šè¿‡Hugging Faceä¸‹è½½:")
        print("pip install transformers")
        print("from transformers import AutoModel")
        print("model = AutoModel.from_pretrained('nvidia/MambaVision-T-1K')")
        
        # åˆ›å»ºä¸‹è½½è„šæœ¬
        download_script = """
# NVIDIA MambaVisionä¸‹è½½è„šæœ¬
from transformers import AutoImageProcessor, AutoModel
import torch

# å¯é€‰çš„æ¨¡å‹å¤§å°
models = {
    'tiny': 'nvidia/MambaVision-T-1K',      # ~31M parameters
    'small': 'nvidia/MambaVision-S-1K',     # ~50M parameters  
    'base': 'nvidia/MambaVision-B-1K',      # ~93M parameters
}

# ä¸‹è½½Tinyæ¨¡å‹ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰
model_name = models['tiny']
print(f"æ­£åœ¨ä¸‹è½½: {model_name}")

processor = AutoImageProcessor.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# ä¿å­˜åˆ°æœ¬åœ°
torch.save(model.state_dict(), 'mambavision_tiny_1k.pth')
print("âœ… NVIDIA MambaVision Tiny ä¸‹è½½å®Œæˆ")
"""
        
        with open("download_nvidia_mambavision.py", "w", encoding="utf-8") as f:
            f.write(download_script)
            
        print("âœ… å·²åˆ›å»º download_nvidia_mambavision.py")
        print("ğŸ’¡ è¿è¡Œæ­¤è„šæœ¬ä¸‹è½½NVIDIA MambaVisionæ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºä¸‹è½½è„šæœ¬å¤±è´¥: {e}")

def create_model_integration_guide():
    """åˆ›å»ºæ¨¡å‹æ•´åˆæŒ‡å—"""
    print("\nğŸ“– åˆ›å»ºæ¨¡å‹æ•´åˆæŒ‡å—...")
    
    integration_guide = '''
# Vision Mambaé¢„è®­ç»ƒæ¨¡å‹æ•´åˆæŒ‡å—

## æ–¹æ¡ˆ1: ä½¿ç”¨MambaÂ® (æ¨è)

MambaÂ®æ˜¯æ”¹è¿›ç‰ˆçš„Vision Mambaï¼Œå…·æœ‰æ›´å¥½çš„æ”¶æ•›æ€§å’Œæ€§èƒ½ã€‚

### 1. ä¸‹è½½MambaÂ®é¢„è®­ç»ƒæ¨¡å‹
```bash
# è®¿é—®å®˜æ–¹GitHubä¸‹è½½
git clone https://github.com/wangf3014/Mamba-Reg.git
cd Mamba-Reg
# ä¸‹è½½é¢„è®­ç»ƒæƒé‡ï¼ˆæŒ‰ç…§é¡¹ç›®è¯´æ˜ï¼‰
```

### 2. æ•´åˆåˆ°æ‚¨çš„é¡¹ç›®
```python
# ä¿®æ”¹ models/FSRA/backbones/vision_mamba_lite.py
# æˆ–åˆ›å»ºæ–°çš„ vision_mambar.py

class VisionMambaR(nn.Module):
    """MambaÂ® - Vision Mamba with Registers"""
    def __init__(self, img_size=224, patch_size=16, **kwargs):
        super().__init__()
        # æ·»åŠ register tokensæ”¯æŒ
        self.num_registers = 12  # MambaÂ®çš„å…³é”®ç‰¹æ€§
        # ... å…¶ä½™å®ç°
    
    def load_mambar_pretrained(self, pretrain_path):
        """åŠ è½½MambaÂ®é¢„è®­ç»ƒæƒé‡"""
        checkpoint = torch.load(pretrain_path, map_location='cpu')
        # å¤„ç†æƒé‡æ˜ å°„
        self.load_state_dict(checkpoint, strict=False)
```

### 3. è®­ç»ƒå‘½ä»¤
```bash
python train.py --backbone MAMBA-R --pretrain_path pretrained_models/mambar_small.pth --lr 0.0001 --name mambar_experiment
```

## æ–¹æ¡ˆ2: ä½¿ç”¨NVIDIA MambaVision

### 1. å®‰è£…ä¾èµ–
```bash
pip install transformers timm
```

### 2. ä¸‹è½½æ¨¡å‹
```python
from transformers import AutoModel
model = AutoModel.from_pretrained('nvidia/MambaVision-T-1K')
torch.save(model.state_dict(), 'mambavision_tiny.pth')
```

### 3. é€‚é…åˆ°two_view_net
```python
# ä¿®æ”¹ models/model.py
class two_view_net(nn.Module):
    def __init__(self, opt, class_num, **kwargs):
        super().__init__()
        if 'MAMBA-VISION' in opt.backbone:
            # ä½¿ç”¨NVIDIA MambaVision
            from transformers import AutoModel
            pretrained = AutoModel.from_pretrained('nvidia/MambaVision-T-1K')
            self.model_1 = adapt_mambavision_for_fsra(pretrained, class_num)
        else:
            self.model_1 = make_transformer_model(opt, class_num, **kwargs)
```

## æ–¹æ¡ˆ3: ç«‹å³è§£å†³æ”¶æ•›é—®é¢˜

å¦‚æœæ€¥éœ€è§£å†³å½“å‰è®­ç»ƒé—®é¢˜ï¼Œå»ºè®®ï¼š

### 1. ä¸´æ—¶ä½¿ç”¨ViTé¢„è®­ç»ƒ
```bash
# å…ˆç”¨ViTéªŒè¯æ•°æ®å’Œä»£ç æ²¡é—®é¢˜
python train.py --backbone VIT-S --lr 0.01 --name vit_baseline
```

### 2. è°ƒæ•´Mambaè®­ç»ƒå‚æ•°
```bash
# ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡å’Œæ›´å¥½çš„ä¼˜åŒ–å™¨
python train.py --backbone MAMBA-LITE --optimizer adamw --lr 0.01 --name mamba_fixed
```

### 3. æ·»åŠ é¢„çƒ­å’Œæ¢¯åº¦è£å‰ª
```python
# åœ¨train.pyä¸­æ·»åŠ 
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

## æ¨èæ–¹æ¡ˆä¼˜å…ˆçº§

1. **ç«‹å³æµ‹è¯•**: ä½¿ç”¨ViT-SéªŒè¯ä»£ç æ­£ç¡®æ€§
2. **çŸ­æœŸæ–¹æ¡ˆ**: è°ƒæ•´MAMBA-LITEè®­ç»ƒå‚æ•°  
3. **é•¿æœŸæ–¹æ¡ˆ**: æ•´åˆMambaÂ®æˆ–NVIDIA MambaVisioné¢„è®­ç»ƒæ¨¡å‹

## é¢„æœŸæ”¹è¿›æ•ˆæœ

- ViT-S: ~75-80% å‡†ç¡®ç‡ï¼ˆç¨³å®šåŸºçº¿ï¼‰
- MAMBA-LITE + è°ƒå‚: ~65-70% å‡†ç¡®ç‡
- MambaÂ® + é¢„è®­ç»ƒ: ~75-83% å‡†ç¡®ç‡
- NVIDIA MambaVision: ~80-85% å‡†ç¡®ç‡
'''
    
    with open("MAMBA_INTEGRATION_GUIDE.md", "w", encoding="utf-8") as f:
        f.write(integration_guide)
    
    print("âœ… å·²åˆ›å»º MAMBA_INTEGRATION_GUIDE.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Vision Mambaé¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å’Œæ•´åˆå·¥å…·")
    print("=" * 60)
    
    # 1. ä¸‹è½½MambaÂ®æ¨¡å‹å ä½ç¬¦
    mambar_models = download_mambar_models()
    
    # 2. åˆ›å»ºNVIDIA MambaVisionä¸‹è½½è„šæœ¬
    download_nvidia_mambavision()
    
    # 3. åˆ›å»ºæ•´åˆæŒ‡å—
    create_model_integration_guide()
    
    print("\nğŸ‰ å‡†å¤‡å·¥ä½œå®Œæˆï¼")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print("1. ğŸš€ ç«‹å³æµ‹è¯•: python train.py --backbone VIT-S --lr 0.01 --name vit_test")
    print("2. ğŸ”§ ä¿®å¤Mamba: python train.py --backbone MAMBA-LITE --lr 0.01 --name mamba_fixed")
    print("3. ğŸ“¥ ä¸‹è½½é¢„è®­ç»ƒ: æŒ‰ç…§ MAMBA_INTEGRATION_GUIDE.md æ“ä½œ")
    print("4. ğŸ“– è¯¦ç»†æŒ‡å—: æŸ¥çœ‹ MAMBA_INTEGRATION_GUIDE.md")

if __name__ == "__main__":
    main() 