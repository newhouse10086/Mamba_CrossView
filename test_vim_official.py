#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å®˜æ–¹Vision Mamba (Vim)å®ç°
éªŒè¯æ¨¡å‹åˆ›å»ºã€æƒé‡åŠ è½½å’Œå‰å‘ä¼ æ’­

ç”¨æ³•:
python test_vim_official.py
"""

import torch
import torch.nn as nn
import os
import sys
sys.path.append('.')

from models.FSRA.backbones.vim_official import (
    vim_tiny_patch16_224_FSRA, 
    vim_small_patch16_224_FSRA, 
    VisionMambaOfficial
)

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("=" * 60)
    print("ğŸ”§ æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        # æµ‹è¯•Vim-Tiny
        print("\nğŸ“¦ åˆ›å»ºVim-Tinyæ¨¡å‹...")
        model_tiny = vim_tiny_patch16_224_FSRA(
            img_size=(256, 256), 
            stride_size=16, 
            drop_rate=0.0, 
            local_feature=False
        )
        print(f"âœ… Vim-Tinyåˆ›å»ºæˆåŠŸ")
        print(f"   - å‚æ•°é‡: {sum(p.numel() for p in model_tiny.parameters()):,}")
        print(f"   - åµŒå…¥ç»´åº¦: {model_tiny.embed_dim}")
        
        # æµ‹è¯•Vim-Small
        print("\nğŸ“¦ åˆ›å»ºVim-Smallæ¨¡å‹...")
        model_small = vim_small_patch16_224_FSRA(
            img_size=(256, 256), 
            stride_size=16, 
            drop_rate=0.0, 
            local_feature=False
        )
        print(f"âœ… Vim-Smallåˆ›å»ºæˆåŠŸ")
        print(f"   - å‚æ•°é‡: {sum(p.numel() for p in model_small.parameters()):,}")
        print(f"   - åµŒå…¥ç»´åº¦: {model_small.embed_dim}")
        
        return model_tiny, model_small
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def test_forward_pass(model, model_name):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print(f"\nğŸš€ æµ‹è¯•{model_name}å‰å‘ä¼ æ’­...")
    
    try:
        # åˆ›å»ºè¾“å…¥æ•°æ®
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 256, 256)
        print(f"   è¾“å…¥å½¢çŠ¶: {input_tensor.shape}")
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            output = model(input_tensor)
            
        print(f"âœ… {model_name}å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # æ£€æŸ¥è¾“å‡ºç»´åº¦
        expected_patches = (256 // 16) * (256 // 16)  # 16x16 patches
        expected_seq_len = expected_patches + 1  # +1 for cls token
        
        if output.shape[1] == expected_seq_len:
            print(f"   âœ… è¾“å‡ºåºåˆ—é•¿åº¦æ­£ç¡®: {expected_seq_len}")
        else:
            print(f"   âš ï¸  è¾“å‡ºåºåˆ—é•¿åº¦: {output.shape[1]}, é¢„æœŸ: {expected_seq_len}")
            
        return True
        
    except Exception as e:
        print(f"âŒ {model_name}å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_pretrained_loading():
    """æµ‹è¯•é¢„è®­ç»ƒæƒé‡åŠ è½½"""
    print("\nğŸ”„ æµ‹è¯•é¢„è®­ç»ƒæƒé‡åŠ è½½...")
    
    pretrained_path = "vim_t_midclstok_ft_78p3acc.pth"
    
    if not os.path.exists(pretrained_path):
        print(f"âš ï¸  é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {pretrained_path}")
        print("   è¯·ç¡®ä¿vim_t_midclstok_ft_78p3acc.pthåœ¨é¡¹ç›®æ ¹ç›®å½•")
        return False
        
    try:
        # åˆ›å»ºæ¨¡å‹
        model = vim_tiny_patch16_224_FSRA(
            img_size=(224, 224),  # ä½¿ç”¨æ ‡å‡†ImageNetå°ºå¯¸æµ‹è¯•
            stride_size=16,
            drop_rate=0.0,
            local_feature=False
        )
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæƒé‡: {pretrained_path}")
        model.load_param(pretrained_path)
        
        print("âœ… é¢„è®­ç»ƒæƒé‡åŠ è½½æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ é¢„è®­ç»ƒæƒé‡åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_fsra_compatibility():
    """æµ‹è¯•FSRAæ¡†æ¶å…¼å®¹æ€§"""
    print("\nğŸ”— æµ‹è¯•FSRAæ¡†æ¶å…¼å®¹æ€§...")
    
    try:
        from models.FSRA.make_model import build_transformer
        
        # åˆ›å»ºoptå¯¹è±¡æ¨¡æ‹Ÿ
        class MockOpt:
            def __init__(self):
                self.backbone = "VIM-TINY"
                self.pretrain_path = "vim_t_midclstok_ft_78p3acc.pth"
        
        opt = MockOpt()
        num_classes = 701  # University-1652æ•°æ®é›†ç±»åˆ«æ•°
        
        # æµ‹è¯•build_transformer
        print("ğŸ—ï¸  æµ‹è¯•build_transformer...")
        transformer_model = build_transformer(opt, num_classes, block=4, return_f=False)
        
        print("âœ… FSRAæ¡†æ¶å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        print(f"   - è¾“å…¥ç»´åº¦: {transformer_model.in_planes}")
        print(f"   - åˆ†ç±»å™¨æ•°é‡: {transformer_model.block}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        input_tensor = torch.randn(2, 3, 256, 256)
        with torch.no_grad():
            output = transformer_model(input_tensor)
            
        print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape if not isinstance(output, list) else [o.shape for o in output]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ FSRAæ¡†æ¶å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ å®˜æ–¹Vision Mamba (Vim)å®ç°æµ‹è¯•")
    print("åŸºäº: https://github.com/hustvl/Vim")
    print("=" * 60)
    
    all_tests_passed = True
    
    # 1. æµ‹è¯•æ¨¡å‹åˆ›å»º
    model_tiny, model_small = test_model_creation()
    if model_tiny is None or model_small is None:
        all_tests_passed = False
    
    # 2. æµ‹è¯•å‰å‘ä¼ æ’­
    if model_tiny is not None:
        if not test_forward_pass(model_tiny, "Vim-Tiny"):
            all_tests_passed = False
            
    if model_small is not None:
        if not test_forward_pass(model_small, "Vim-Small"):
            all_tests_passed = False
    
    # 3. æµ‹è¯•é¢„è®­ç»ƒæƒé‡åŠ è½½
    if not test_pretrained_loading():
        all_tests_passed = False
        
    # 4. æµ‹è¯•FSRAå…¼å®¹æ€§
    if not test_fsra_compatibility():
        all_tests_passed = False
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    if all_tests_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("   1. æ¨èä½¿ç”¨VIM-TINYä½œä¸ºä¸»è¦backbone")
        print("   2. å­¦ä¹ ç‡å»ºè®®: 0.0003-0.0005")
        print("   3. é¢„è®­ç»ƒæƒé‡: vim_t_midclstok_ft_78p3acc.pth")
        print("\nğŸš€ è®­ç»ƒå‘½ä»¤ç¤ºä¾‹:")
        print("   python train.py --backbone VIM-TINY --pretrain_path vim_t_midclstok_ft_78p3acc.pth --lr 0.0005")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return 1
        
    return 0


if __name__ == "__main__":
    exit(main()) 