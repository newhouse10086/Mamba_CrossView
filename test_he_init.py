"""
æµ‹è¯•VisionMambaLiteçš„HE(Kaiming)åˆå§‹åŒ–
"""
import torch
import numpy as np
from models.FSRA.backbones.vision_mamba_lite import vision_mamba_lite_small_patch16_224_FSRA

def test_he_initialization():
    print("ğŸ” æµ‹è¯•VisionMambaLiteçš„HE(Kaiming)åˆå§‹åŒ–...")
    
    # åˆ›å»ºæ¨¡å‹
    model = vision_mamba_lite_small_patch16_224_FSRA(
        img_size=(256, 256), 
        stride_size=16, 
        drop_rate=0.0, 
        local_feature=False
    )
    
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"ğŸ“Š æ€»å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # æ£€æŸ¥å„å±‚çš„åˆå§‹åŒ–ç»Ÿè®¡
    print("\nğŸ“ˆ æƒé‡åˆå§‹åŒ–ç»Ÿè®¡:")
    print("=" * 70)
    
    layer_stats = []
    
    for name, param in model.named_parameters():
        if param.requires_grad and len(param.shape) >= 2:
            weight_data = param.data.cpu().numpy()
            mean = np.mean(weight_data)
            std = np.std(weight_data)
            min_val = np.min(weight_data)
            max_val = np.max(weight_data)
            
            layer_stats.append({
                'name': name,
                'shape': tuple(param.shape),
                'mean': mean,
                'std': std,
                'min': min_val,
                'max': max_val
            })
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    for stat in layer_stats[:15]:  # åªæ˜¾ç¤ºå‰15å±‚
        print(f"ğŸ”¹ {stat['name']:<40} | Shape: {str(stat['shape']):<15} | Mean: {stat['mean']:.4f} | Std: {stat['std']:.4f}")
    
    if len(layer_stats) > 15:
        print(f"... è¿˜æœ‰ {len(layer_stats) - 15} å±‚æœªæ˜¾ç¤º")
    
    # æ£€æŸ¥HEåˆå§‹åŒ–çš„ç†è®ºæ ‡å‡†å·®
    print("\nğŸ¯ HEåˆå§‹åŒ–éªŒè¯ (é€‚åˆReLU/SiLUæ¿€æ´»):")
    print("=" * 70)
    
    for stat in layer_stats[:8]:  # æ£€æŸ¥å‰8å±‚
        shape = stat['shape']
        if len(shape) == 2:  # Linearå±‚
            fan_in, fan_out = shape[1], shape[0]
            # HE uniform (fan_in mode): std = sqrt(6/fan_in)
            # HE normal (fan_out mode): std = sqrt(2/fan_out)
            he_std_fan_in = np.sqrt(2.0 / fan_in)  # HE normal fan_in mode
            he_std_fan_out = np.sqrt(2.0 / fan_out)  # HE normal fan_out mode
            he_uniform_std = np.sqrt(6.0 / fan_in)  # HE uniform fan_in mode
            
            print(f"ğŸ“ {stat['name']:<40}")
            print(f"   HE std (fan_in): {he_std_fan_in:.4f} | HE std (fan_out): {he_std_fan_out:.4f}")
            print(f"   HE uniform std: {he_uniform_std:.4f} | å®é™…std: {stat['std']:.4f}")
            
            # åˆ¤æ–­æœ€æ¥è¿‘å“ªç§åˆå§‹åŒ–
            diff_fan_in = abs(stat['std'] - he_std_fan_in)
            diff_fan_out = abs(stat['std'] - he_std_fan_out)
            diff_uniform = abs(stat['std'] - he_uniform_std)
            
            if diff_uniform < min(diff_fan_in, diff_fan_out):
                print(f"   ğŸ¯ æœ€æ¥è¿‘: HE uniform (fan_in) | å·®å¼‚: {diff_uniform:.4f}")
            elif diff_fan_in < diff_fan_out:
                print(f"   ğŸ¯ æœ€æ¥è¿‘: HE normal (fan_in) | å·®å¼‚: {diff_fan_in:.4f}")
            else:
                print(f"   ğŸ¯ æœ€æ¥è¿‘: HE normal (fan_out) | å·®å¼‚: {diff_fan_out:.4f}")
                
        elif len(shape) == 4:  # Conv2då±‚
            fan_in = shape[1] * shape[2] * shape[3]
            fan_out = shape[0] * shape[2] * shape[3]
            he_std_fan_out = np.sqrt(2.0 / fan_out)  # HE normal fan_out mode
            
            print(f"ğŸ“ {stat['name']:<40}")
            print(f"   HE std (fan_out): {he_std_fan_out:.4f} | å®é™…std: {stat['std']:.4f} | æ¯”ç‡: {stat['std']/he_std_fan_out:.2f}")
        
        print()
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\nğŸš€ æµ‹è¯•å‰å‘ä¼ æ’­:")
    print("=" * 70)
    
    model.eval()
    with torch.no_grad():
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(2, 3, 256, 256)
        print(f"ğŸ“¥ è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        try:
            output = model(test_input)
            print(f"ğŸ“¤ è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # æ£€æŸ¥è¾“å‡ºç»Ÿè®¡
            output_stats = {
                'mean': output.mean().item(),
                'std': output.std().item(),
                'min': output.min().item(),
                'max': output.max().item()
            }
            
            print(f"ğŸ“Š è¾“å‡ºç»Ÿè®¡: Mean={output_stats['mean']:.4f}, Std={output_stats['std']:.4f}")
            print(f"            Min={output_stats['min']:.4f}, Max={output_stats['max']:.4f}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if abs(output_stats['mean']) > 1.0:
                print("âš ï¸  è­¦å‘Š: è¾“å‡ºå‡å€¼è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨åˆå§‹åŒ–é—®é¢˜")
            elif abs(output_stats['mean']) < 0.2 and output_stats['std'] > 0.1:
                print("âœ… è¾“å‡ºç»Ÿè®¡æ­£å¸¸ï¼ŒHEåˆå§‹åŒ–å·¥ä½œè‰¯å¥½")
            
            # æ£€æŸ¥æ¿€æ´»å€¼çš„åˆ†å¸ƒ
            print(f"ğŸ’¡ HEåˆå§‹åŒ–ç‰¹ç‚¹: é€‚åˆReLUæ—æ¿€æ´»å‡½æ•°(å¦‚SiLU)ï¼Œä¿æŒå‰å‘ä¼ æ’­æ—¶æ¿€æ´»å€¼æ–¹å·®ç¨³å®š")
            
            print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return False
    
    # æµ‹è¯•æ¢¯åº¦ä¼ æ’­
    print("\nğŸ”„ æµ‹è¯•æ¢¯åº¦ä¼ æ’­:")
    print("=" * 70)
    
    model.train()
    try:
        test_input = torch.randn(1, 3, 256, 256, requires_grad=True)
        output = model(test_input)
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„loss
        loss = output.mean()
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦ç»Ÿè®¡
        grad_stats = []
        for name, param in model.named_parameters():
            if param.grad is not None and len(param.shape) >= 2:
                grad_data = param.grad.data.cpu().numpy()
                grad_mean = np.mean(np.abs(grad_data))
                grad_std = np.std(grad_data)
                grad_stats.append({
                    'name': name,
                    'grad_mean': grad_mean,
                    'grad_std': grad_std
                })
        
        print(f"ğŸ“ˆ æ¢¯åº¦ç»Ÿè®¡ (å‰5å±‚):")
        for stat in grad_stats[:5]:
            print(f"   {stat['name']:<40} | Mean: {stat['grad_mean']:.6f} | Std: {stat['grad_std']:.6f}")
        
        # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å¥åº·
        all_grad_means = [s['grad_mean'] for s in grad_stats]
        if all_grad_means:
            avg_grad = np.mean(all_grad_means)
            if avg_grad > 1e-6 and avg_grad < 1e-2:
                print("âœ… æ¢¯åº¦åˆ†å¸ƒå¥åº·ï¼ŒHEåˆå§‹åŒ–æœ‰åŠ©äºæ¢¯åº¦ç¨³å®šä¼ æ’­")
            elif avg_grad < 1e-6:
                print("âš ï¸  æ¢¯åº¦è¾ƒå°ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜")
            else:
                print("âš ï¸  æ¢¯åº¦è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸é—®é¢˜")
        
        print("âœ… æ¢¯åº¦ä¼ æ’­æµ‹è¯•æˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ æ¢¯åº¦ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ HEåˆå§‹åŒ–æµ‹è¯•å®Œæˆ!")
    return True

if __name__ == "__main__":
    success = test_he_initialization()
    if success:
        print("\nğŸš€ HEåˆå§‹åŒ–éªŒè¯å®Œæˆï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒäº†!")
        print("\nğŸ’¡ HEåˆå§‹åŒ–çš„ä¼˜åŠ¿:")
        print("   - ä¸“ä¸ºReLUæ—æ¿€æ´»å‡½æ•°(åŒ…æ‹¬SiLU)è®¾è®¡")
        print("   - æ›´å¥½åœ°ä¿æŒæ¿€æ´»å€¼æ–¹å·®")
        print("   - æœ‰åŠ©äºé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸")
        print("   - é€šå¸¸æ”¶æ•›æ›´å¿«æ›´ç¨³å®š")
        
        print("\næ¨èè®­ç»ƒå‘½ä»¤:")
        print("python train.py --backbone MAMBA-LITE --lr 0.001 --batchsize 32 --gpu_ids 0")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆå§‹åŒ–ä»£ç ") 